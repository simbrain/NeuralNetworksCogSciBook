\chapter{Unsupervised Learning in Recurrent Networks}\label{ch_unsupervised_recurrent}
\chapterauthor{Jeff Yoshimi}

% Run the matrix multiplication material through here so that it comes back and ties together
% Add IAC. It is the initial motivating example and the underlying idea is in the background here, though in IAC a but more dynamic emphasis as we settle into things. The "answers" are attractors. The transients have meaning. Spivey and JTrace people do work on this. 
% Boltzmann machine reference?  And equivalence to hopfield. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7823871/

\section{Introduction}

In this chapter, we consider recurrent networks trained using the Hebb rule to complete patterns. This complements the discussion of unsupervised learning in feed-forward networks in chapter \extref{ch_unsupervised} with an analysis of unsupervised learning in recurrent networks. We will see that the tools of dynamical systems theory (chapter \extref{ch_dst}) are quite useful in this context. In chapter \extref{ch_supervised_recurrent} we discuss more complex recurrent networks and their applications to psychology, neuroscience, and engineering.
  
\section{Hebbian Pattern Association for Recurrent Networks}

We now consider a \emph{recurrent} network trained using the Hebb rule. When the Hebb rule is used in a recurrent network, connections between active nodes will be strengthened, and the result is a kind of trace of the pattern. If the weights are then clamped to prevent further learning (recall how sensitive Hebbian learning is), a fragment of the pattern, a ``cue'', can then be used to recreate the entire pattern. An example that makes the idea clear is in Fig. \ref{patternCompletionL}, where the residue of past training on an ``L''-shaped pattern (a ``memory trace'') is evident. When the network is updated, it is obvious that the activation will fill in the L-shape. 

Because they associate parts of a pattern with a whole pattern, these networks are sometimes thought of as auto-associators, or ``self''-associators.
% Link to ff auto-associator; really kind of a separate category

\begin{figure}[h]
\centering
\includegraphics[scale=.45]{./images/patternCompletion_Cue}
\caption[Simbrain screenshot.]{Cued recall of an ``L'' shaped pattern. Notice that the ``L'' pattern is visible in the red weights, which indicate how the pattern will be completed. In the past, those neurons fired together, so they were wired together by the Hebb rule.}
\label{patternCompletionL}
\end{figure}

Just as it is fairly easy to train feed-forward pattern associators using the Hebb rule (see chapter \extref{ch_unsupervised}), it is fairly easy to train recurrent pattern associators in this way.  For practice, try using the self-contained Simbrain tutorials \emph{autoAssociatorPart1.zip} and \emph{autoAssociatorPart2.zip}, created by Alex Holcombe.\footnote{In Simbrain press \emph{open workspaces} and navigate to the \emph{courseMaterials} folder.}
% TODO: Add in a step-by step guide here, as in the other chapter

% Citation to scientific literature below.
These ideas can be used to understand conceptually how visual image completion might work. When we see a fragment of a familiar image or visual scene, we often ``fill in the rest''. This can be understood in terms of trained associations in a recurrent network where each node corresponds to a pixel. When a pattern is learned, all the correlations between pixels are encoded by strengthening corresponding connections using the Hebb rule. An example of a recurrent auto-associator for visual memories is shown in Fig. \ref{patternCompletionBeerDog}. It's the same idea as with the simple ``L'' pattern in Fig. \ref{patternCompletionL}, but with a much larger network, containing half a million rather a few hundred weights. In each case, learning a memory amounts to strengthening co-active nodes in a grid of nodes. In both cases, a partial cue triggers the completion of a stored pattern. The formation and recall of visual memories can be understood in these terms.  
%\footnote{The small network has $(4 \cdot 4) = 16$ nodes, and thus $16^2 = 256$ weights; the larger network has $(130 \cdot 180) = 23,400$ nodes and thus $23,400^2 = 547,560,000$ weights.} <- Check these numbers. The small net does not self connections, not sure about the larger one

\begin{figure}[h]
\centering
\includegraphics[scale=.8]{./images/patternCompletionBeerDog.png}
\caption[From Hertz, Krogh, and Palmer, 1991 \cite{hertz1991introduction}.]{Pattern completion in a recurrent network with $130 \cdot 180 = 23,400$ nodes. The left-most image in each row shows the initial cue. The middle image shows the network part-way through the pattern completion process. The right image shows the final image. From Hertz et al. 1991. The network is a Hopfield network, which uses a variant on the Hebb rule.}
\label{patternCompletionBeerDog}
\end{figure}


\begin{figure}[h]
\centering
\frame{\includegraphics[scale=.5]{./images/attractorsBeerDog.png}}
\caption[Pamela Payne, using elements from Hertz, Krogh, and Palmer, 1991 \cite{hertz1991introduction}.]{Schematic diagram of the attractors and basins of attraction for the images shown in Fig. \ref{patternCompletionBeerDog}. Fragments of images correspond to initial conditions, that evolve under the network dynamics to completed images, which correspond to attracting fixed points.}
\label{beerDogAttractors}
\end{figure}

% Reinforce the links below with a bulleted list (see learning objectives). Also add oscillations -> n-cycles.
Figure \ref{beerDogAttractors} shows how pattern completion in recurrent auto-associators can be understood in terms of   dynamical systems theory (also see chapter \extref{ch_dst}). Each new pattern the network is trained on becomes a fixed point attractor in its activation space. The beer and dog images on the right of Fig. \ref{patternCompletionBeerDog} are fixed point attractors in the 23,400-dimensional activation space of that network. The ``L'' visible as a trace in Fig. \ref{patternCompletionL} is a fixed point attractor of the 16-dimensional activation space of that network. A cue corresponds to an initial condition. The single beer bottle and dog's ear in Fig. \ref{patternCompletionBeerDog} are initial conditions, as is the upper part of the ``L'' in Fig. \ref{patternCompletionL}. Recall corresponds to following an orbit through the activation space. The final memory is the attractor corresponding to whatever basin of attraction the initial condition was in. Thus, on this model, learning a new pattern via Hebb's rule corresponds to adding a new attractor to the network's state space.\footnote{Thus, learning in these cases also counts as a bifurcation, since this corresponds to a change of parameters (weights) that produces a change in the topological structure of the orbits in the state space.}

% Local representations
%The advantage of thinking about recurrent auto-associators in terms of images is that it's immediately, visually obvious how they work. But recurrent auto-associators can also be understood more abstractly. If we think of each node in an auto-associator as one memory, then we can simply think about an auto-associator as connecting these localist memories together. Such a network, once trained, is a lot like the IAC networks (e.g. the Jets and Sharks model) discussed in chapter \extref{ch_intro}. In such a network attributes of gang members---their job, their name, their age, etc---are recalled when some of those attributes are activated and the network is run. This is exactly what happens in a recurrent auto-associator. But whereas weights in an IAC network are set by hand, the Hebb rule shows how they can be \emph{learned}. You set all the weights to be connected to ``on'' and then apply the rule, and the associations are encoded.

\section{Some features of recurrent auto-associators}

First, they perform fairly well even if some synapses are removed (\glossary{graceful degradation}) or if you add noise to the inputs.

Second, the memories you train the recurrent network on can interfere with one another. Small networks trained using \glossary{binary vector} inputs (patterns of 0's and 1's, as in see Figure \ref{binary}) cannot easily learn more than one memory. If a second pattern overlaps the first (in which case the two input vectors are not \glossary{orthogonal}), then during recall any partial version of either pattern will produce the \emph{conjunction} of the two patterns. This is sometimes called \glossary{cross talk}. To address the problem, we can use \glossary {bipolar vector} patterns (see Figures \ref{binary} and \ref{bipolar} to see how binary and bipolar patterns compare), in which the ``off'' neurons are set to -1. The reason this helps is that the network is now learning not only to recreate a pattern of correlated activations, but also to \emph{inhibit} activations inconsistent with the current pattern. The ``on'' nodes are connected to the ``off'' nodes with negative weights. Thus, during recall, activating one pattern will inhibit other patterns. This in turn makes it possible to store overlapping patterns. One pattern simultaneously represses the other. 
% If you store two patterns with just one overlapping unit, for example, you will notice that both can be independently recalled. 
% Add in Hopfield's trick 2V -1  here to convert binary to bipolar behind the scenes. See "Week 11 Hw (Hopfield")

\begin{figure}[h]
\centering
\includegraphics[scale=.6]{./images/hebb_binary_9.png}
\caption[Simbrain screenshot.]{An auto associative network trained on a single binary pattern using Hebb's rule. Notice that only weights between co-active nodes have been strengthened. Since the other nodes have activations of 0, weights to and from them are not changed.}
\label{binary}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=.6]{./images/hebb_bipolar_9.png}
\caption[Simbrain screenshot]{Bipolar version of pattern from Fig. \ref{binary}, after training on a bipolar version of the same pattern. Notice how some of the weights have turned blue. Thus, when the pattern is recreated incompatible patterns will be inhibited. This version of the network can learn several patterns.}
\label{bipolar}
\end{figure}
% Say more. See Hopfield paper. Potential for recall is proportional to hamming error between patterns. Something like that.

Third, when you train a recurrent network, you will sometimes notice new patterns, which are byproducts of other patterns: this is sometimes called a \glossary{spurious memory}. A common form of spurious memory in a recurrent network is the \glossary{antipattern} of a pattern, which is formed by changing every activation to its opposite value: swapping 0's and 1's in a binary pattern, or -1's and 1's in a bipolar pattern. For example the antipattern of $(1,-1,1)$ is $(-1,1,-1)$.\footnote{One way to get a feel for this is to use a projection to see all the stored and spurious patterns, which are attractors of the network. Often these will appear to be symmetrically positioned vertices of a hypercube.} 

Finally, these networks tend to oscillate. If you try multiple initial conditions in a recurrent network trained using the Hebb rule, it may sometimes oscillate through an $n$-cycle rather than settling in to a fixed point attractor. In our study of dynamical systems in chapter \extref{ch_dst} we saw that oscillations---i.e. attracting periodic orbits---often appear in recurrent networks. Using the Hebb rule can store a fixed point attractor memory, but un-desired $n$-cycles can come along for the ride. Hopfield networks, discussed next, avoid this problem.

% You can also analyze the network using dynamical systems theory. If you put the network in to random activation states (by selecting all neurons and pressing the randomize button) and iterate, you will note that it either settles into the pattern you created or to its ``dual,'' a pattern of -1's on the same neurons (this is also called a ``spurious'' memory). You can visualize this by opening a projection plot. Any point in activation space will evolve to one of these two attracting fixed points. Thus you have, via learning, created two attractors corresponding to this pattern and its dual.

% In terms of dynamical systems theory, what is happening is that we are observing periodic orbits in the network's activation space. Hopfield networks, discussed next, solve the problem of oscillations, but most of the other problems remain.

\section{Hopfield Networks}

% Reference below. 
A special type of recurrent, auto associative, Hebbian network is a Hopfield network.\footnote{Hopfield networks are important historically. When John Hopfield, a physicist, introduced them in the 1970s it brought the existing engineering literature on neural networks and the formalisms in physics into greater contact with one another. Hopfield also pioneered the use of dynamical systems theory in neural networks \cite{hopfield1982neural}. For this work he was awarded the Nobel Prize in 2024. There were precursors to Hopfield's work, in particular Amari \cite{amari1972learning}.}  Hopfield networks have no self-connections and their weights are always symmetrical ($w_{i,j} = w_{j,i}$ for every weight in the network). The symmetric weight matrices and the special way they are updated gets rid of unwanted oscillations.
% Footnote on what asynchronous or "random" update is.
% Rojas has some discussion of this in his book
% Mention triangular matrices

\begin{figure}[h]
\centering
\includegraphics[scale=.34]{./images/Hopfield.png}
\caption[Simbrain screenshot]{Hopfield network trained on the pattern for a ``Z''. Though a binary pattern is displayed behind the scenes this network uses bipolar patterns, with -1's where 0s are.}
\label{F:hopfield}
\end{figure}

% TODO: Check this. Does not work in practice? Is that capacity with or without antipatterns?
A Hopfield network with 80 nodes is shown in Fig. \ref{F:hopfield} after it has retrieved one of the 4 memories it was trained on, a memory corresponding to the letter ``Z''. The theoretical memory capacity of Hopfield networks has been estimated to be 15\%  of its number of nodes.\footnote{A discussion of storage capacity for associative memories  is in Fausett \cite{fausett1994fundamentals}, p. 140 and section 3.3.4. Also see Hopfield's original discussion at \cite{hopfield1982neural}, p. 2556.}  Thus, a network with 20 nodes should be able to store about $3 = .15 \cdot 20$ memories. Hopfield networks have the advantage of not producing oscillations. However, they do produce spurious memories. To get a feel for how Hopfield networks work, you are encouraged to try the Simbrain simulation \emph{hopfieldNet.zip} or to make and train a Hopfield network from scratch. 
% If you right click on the interaction box for a Hopfield network you will see several commands that make it easy to quickly train a Hopfield network without all the careful clamping and unclamping required in the more generic recurrent networks described above.
